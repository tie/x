package qlex

import (
	"bufio"
	"fmt"
	"io"
	"strings"
)

// A TokenType represents a user-defined category of tokens, like "strings" or
// "numbers". Each Token emitted by a Lexer is associated to a TokenType.
type TokenType int

// A Token may be emitted by a StateFunc to signify that an instance
// of a specific pattern has been found in the input stream.
type Token struct {
	Typ TokenType
	Val string
	Pos Position
	End Position
}

func (t Token) String() string {
	return fmt.Sprintf("[%v %q %v:%v %v:%v]", t.Typ, t.Val, t.Pos.Line, t.Pos.Column, t.End.Line, t.End.Column)
}

// StateFunc represents a state of the Lexer and the corresponding transition
// to the next state.
// From https://talks.golang.org/2011/lex.slide.
type StateFunc func(*Lexer) StateFunc

// The Lexer contains the description of how to scan the input (i.e. the first
// StateFunc to be executed).
type Lexer struct {
	tokens   chan Token      // channel where tokens produced by this lexer are emitted
	state    StateFunc       // current state of the lexer
	reader   *bufio.Reader   // input source
	buffer   strings.Builder // stores the currently read token, before it is emitted
	startPos Position        // position of the beginning of .buffer in .reader
	endPos   Position        // position of the end of .buffer in .reader
}

// A LexerOption is a way to customize the Lexer created by NewLexer.
// See https://commandcenter.blogspot.com/2014/01/self-referential-functions-and-design.html.
type LexerOption func(*Lexer)

// OMaxTokensInAdvance is a LexerOption that sets n as the Lexer.Tokens channel
// buffer's length.
// This is recommended if you are using Lexer.NextToken().
func OMaxTokensInAdvance(n int) LexerOption {
	switch {
	case n > 0:
		return func(l *Lexer) { l.tokens = make(chan Token, n) }
	case n == 0:
		return func(l *Lexer) { l.tokens = make(chan Token) }
	default:
		panic(fmt.Sprintf("expecting a positive integer, got %v", n))
	}
}

// DefaultLexerOptions determines which LexerOptions are always applied by NewLexer.
var DefaultLexerOptions = [...]LexerOption{
	OMaxTokensInAdvance(2),
}

const maxRuneSizeInBytes = 4 // ... since this is utf8.

// NewLexer creates and customizes a Lexer.
// If no ORememberWith option is provided, the result of NewRuneStringMemory is
// used as this lexer's memory.
func NewLexer(input io.Reader, initState StateFunc, options ...LexerOption) *Lexer {
	l := Lexer{
		state:  initState,
		reader: bufio.NewReaderSize(input, maxRuneSizeInBytes),
	}
	for _, option := range DefaultLexerOptions {
		option(&l)
	}
	for _, option := range options {
		option(&l)
	}
	return &l
}

// Tokens returns the channel on which tokens are emitted by the lexer.
func (l Lexer) Tokens() <-chan Token {
	return l.tokens
}

// Run makes the lexer read the entire input and emit all tokens in the
// Lexer.Tokens channel. Run will therefore block until Lexer.Tokens is read,
// so if your design doesn't involve a consumer running in another goroutine,
// you should probably use NextToken instead of Run.
// See https://talks.golang.org/2011/lex.slide for more about this design.
func (l *Lexer) Run() {
	for l.state != nil {
		l.state = l.state(l)
	}
	close(l.tokens)
}

// Lex returns a channel from which you can read the tokens corresponding to the
// input read by your state functions. Under the hood, it creates a Lexer and
// runs it in a goroutine that writes to the channel. Hence, the warning in the
// documentation of Run (about blocking) applies here too.
func Lex(input io.Reader, initState StateFunc, options ...LexerOption) <-chan Token {
	lexer := NewLexer(input, initState, options...)
	go lexer.Run()
	return lexer.tokens
}

// NextToken returns each Token generated by this Lexer in successive calls.
// This function is intended for users that don't want to read from the
// Lexer.Tokens channel directly.
func (l *Lexer) NextToken() (tok Token, eof bool) {
	for l.state != nil {
		select {
		case token := <-l.tokens:
			return token, false
		default:
			l.state = l.state(l)
		}
	}
	return Token{}, true
}
